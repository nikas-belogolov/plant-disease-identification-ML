# -*- coding: utf-8 -*-
"""Plant_disease_identification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18DLR5Tgs0Ihyvs8t8I0t-CqkI7aeH-aW

# Plant disease identification

## Introduction

This project aims to develop a neural network-based image classifier to identify diseases in pepper and potato plants. Leveraging deep learning techniques, the model will be trained to distinguish between healthy plants and those affected by various diseases. This application is crucial for early disease detection and effective crop management, potentially leading to higher yields and reduced losses.

### Goals

1. Identify Diseases: Develop a robust model capable of identifying diseases in pepper and potato plants from images.
2. Learn Image Identification with Neural Networks: Understand the process of building, training, and evaluating an image classification model using neural networks.
3. Understand and Use SHAP Values: Learn what SHAP (SHapley Additive exPlanations) values are and how to use them for model interpretability.

### Dataset

For this project I've used the [PlantVillage Dataset](https://www.kaggle.com/datasets/emmarex/plantdisease) from Kaggle.

The dataset contains images of pepper, tomato and potato plants categorized into different classes, including healthy plants and various disease conditions.

The dataset was truncated to 5 classes for simplicity (2 classes for pepper plants and 3 for potato plants), and split into training, validation, and test sets to ensure the model's robustness and generalizability.

## Setup
"""

!pip install tensorflow numpy seaborn scikit-learn pandas pathlib matplotlib shap PIL

import os
import tensorflow as tf
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from pathlib import Path
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.utils import plot_model
import pandas as pd
import shap
from PIL import Image
import random

from sklearn.metrics import confusion_matrix
from keras.utils import to_categorical

if os.getenv("COLAB_RELEASE_TAG"):
  from google.colab import drive
  drive.mount('/content/drive')
  dir = "/content/drive/MyDrive/PlantVillage_Dataset"
  split_dir = dir + "/split"
  models_dir = dir + "/models"
else:
  dir = "C:\\Users\\belog\\Documents\\PlantVillage_Dataset"
  split_dir = dir + "\\split"
  models_dir = dir + "\\models"

CLASSES = ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']
IMG_SIZE = (128, 128)
EPOCHS = 100
LEARNING_RATE = 0.0001
EARLY_STOPPING_PATIENCE = 5

"""## Train Test Validation Split"""

#הגדרת תיקיות המקור והיעד של הפיצול.
source_dir = "/content/drive/MyDrive/PlantVillage_Dataset"
destination_dir = "/content/drive/MyDrive/PlantVillage_Dataset/split"

#הגדרת התיקיות החדשות בתיקיית היעד והמחלקות השונות
new_folders = ['train', 'test', 'val']
classes = ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']

for folder in new_folders:
    for class_name in classes:
        new_folder_path = os.path.join(destination_dir, folder, class_name)
        Path(new_folder_path).mkdir(parents=True, exist_ok=True)

def split_and_copy_files(source_dir, destination_dir, split_ratios):
    for class_name in classes:
        class_files = os.listdir(os.path.join(source_dir, class_name))
        random.shuffle(class_files)

        num_files = len(class_files)
        train_split = int(num_files * split_ratios[0])
        test_split = int(num_files * split_ratios[1])

        for i, file_name in enumerate(class_files):
            if i < train_split:
                dest_folder = os.path.join(destination_dir, 'train', class_name)
            elif i < train_split + test_split:
                dest_folder = os.path.join(destination_dir, 'test', class_name)
            else:
                dest_folder = os.path.join(destination_dir, 'val', class_name)

            shutil.copy(os.path.join(source_dir, class_name, file_name), dest_folder)
#מימדי הפיצול כמתואר בתא הטקסט מעל תא הקוד
split_ratios = [0.75, 0.15, 0.10]

split_and_copy_files(source_dir, destination_dir, split_ratios)

print("Files copied successfully!")

"""## Explore Dataset"""

classes = ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']

# Sample data (replace this with your actual data)
data = {
    'Label': classes * 3,
    'Split': [],
    'Size': []
}

for split_folder in os.listdir(split_dir):
  for i in range(0,5):
    data["Split"].append(split_folder)
  for class_name in os.listdir(f"{split_dir}/{split_folder}"):
    data["Size"].append(len(os.listdir(f"{split_dir}/{split_folder}/{class_name}")))

# Convert to DataFrame
df = pd.DataFrame(data)

# Plot using catplot
ax = sns.catplot(x='Split', y='Size', hue='Label', data=df, kind='bar', height=8, aspect=1.5)
plt.title('Train-Test-Validation Distribution by Labels')
plt.ylabel('Size')
plt.xlabel('Labels')
sns.move_legend(ax, "upper right")
plt.show()

random_images = []

for class_name in classes:
  choice = random.choice(os.listdir(dir + "/" + class_name))
  random_images.append(f"{dir}/{class_name}/{choice}")

fig, axes = plt.subplots(1, 5, figsize=(18, 4))
for i, path in enumerate(random_images):
    # Load and display the image
    img = plt.imread(path)
    axes[i].imshow(img)
    axes[i].set_title(classes[i])
    axes[i].axis('off')

plt.show()

"""## Data Preprocessing"""

directory = "/content/drive/MyDrive/PlantVillage_Dataset/split"
img_data_generator = ImageDataGenerator(rescale=1./225)

# Define batch size
batch_size = 32

# Set up the image generators using flow_from_directory
train_generator = img_data_generator.flow_from_directory(
    split_dir + '/train',
    target_size=IMG_SIZE,
    batch_size=batch_size,
    class_mode='categorical')

val_generator = img_data_generator.flow_from_directory(
    split_dir + '/val',
    target_size=IMG_SIZE,
    batch_size=batch_size,
    class_mode='categorical')

test_generator = img_data_generator.flow_from_directory(
    split_dir + '/test',
    target_size=IMG_SIZE,
    batch_size=batch_size,
    class_mode='categorical')

"""# Verify that all images are valid"""

# Iterate through each folder
for folder in os.listdir(split_dir + "/train"):
    # Get a list of all image files in the folder
    image_files = os.listdir(split_dir + "/train/" + folder)

    # Iterate through each image file
    for image_file in image_files:
        # Construct the full path to the image file
        image_path = os.path.join(split_dir + "/train/" + folder, image_file)

        # Try to open the image using PIL
        try:
            image = Image.open(image_path)
        except Exception as e:
            os.remove(image_path)
            print(f"Error opening image '{image_path}': {e}")

"""## Model Building"""

def create_model(input_shape):
  model = tf.keras.models.Sequential([
      tf.keras.Input(shape=input_shape), #
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(128, activation='ReLU'),
      tf.keras.layers.Dense(64, activation='ReLU'),
      tf.keras.layers.Dense(32, activation='ReLU'),
      tf.keras.layers.Dense(32, activation='ReLU'),
      tf.keras.layers.Dense(5, activation='softmax')
  ])

  optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)
  model.compile(optimizer=optimizer,
                loss=tf.keras.losses.CategoricalCrossentropy(),
                metrics=['accuracy'])

  return model

def save_model(model_name):
  model.save(f'{models_dir}/{model_name}.keras')

def load_model(model_name):
  return tf.keras.models.load_model(f'{models_dir}/{model_name}')

input_shape = IMG_SIZE + (3,)

model = create_model(input_shape)
model.summary()
plot_model(model, show_shapes=True, show_layer_names=True)

"""## Model Training"""

checkpoint = tf.keras.callbacks.ModelCheckpoint("best_model", save_best_only=True)
stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE)

history = model.fit(train_generator, epochs=EPOCHS, validation_data=val_generator, callbacks=[stop_early, checkpoint])

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot the accuracy over epochs
plt.plot(history.history['loss'], label='Loss Function')
plt.plot(history.history['val_loss'], label='Validation Loss Function')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.locator_params(axis="x", integer=True, tight=True)
plt.show()

"""## Saving and Loading Model"""

save_model("best_model_50EPCH")

models = []
print("enter model number: ")
for i, model in enumerate(os.listdir(models_dir)):
  print(f'{i} {model}')
  models.append(model)

model = load_model(f'{models[int(input())]}')

"""## Model Evaluation

### Evaluate Model

### Confusion Matrix
"""

print("test loss, test acc:", model.evaluate(test_generator))

# Get predictions from the model using the test generator
predictions = model.predict_generator(test_generator)

# Get true labels from the test generator
true_labels = test_generator.classes

# Convert predictions to class labels
predicted_labels = np.argmax(predictions, axis=1)

print("Classification Report:", classification_report(true_labels, predicted_labels))

print("Confusion Matrix:")

# Calculate confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""## Explaining model outputs with SHAP values"""

x_train = []
y_train = []

x_test = []
y_test = []

for _, label in enumerate(os.listdir(split_dir + "/train")):
  for _, file in enumerate(os.listdir(split_dir + "/train/" + label)):
    image = Image.open(split_dir + "/train/" + label + "/" + file)
    image = image.resize(IMG_SIZE)
    image = image.convert('RGB')
    image_array = np.array(image)
    x_train.append(image_array)
    y_train.append(classes.index(label))

for _, label in enumerate(os.listdir(split_dir + "/test")):
  for _, file in enumerate(os.listdir(split_dir + "/test/" + label)):
    image = Image.open(split_dir + "/test/" + label + "/" + file)
    image = image.resize(IMG_SIZE)
    image = image.convert('RGB')
    image_array = np.array(image)
    x_test.append(image_array)
    y_test.append(classes.index(label))

# save as DataX or any other name. But the same element name is to be used while loading it back.
np.savez("/content/drive/MyDrive/PlantVillage_Dataset/mnistlikedataset.npz",x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)

path = "/content/drive/MyDrive/PlantVillage_Dataset/mnistlikedataset.npz"
x_train, y_train, x_test, y_test
with np.load(path) as data:
    #load DataX as train_data
    x_train = data['x_train']
    y_train = data['y_train']
    x_test = data['x_test']
    y_test = data['y_test']

print(x_train.shape)

num_classes = len(CLASSES)
input_shape = IMG_SIZE + (3,)

# Scale images to the [0, 1] range
x_train = x_train.astype("float32") / 255
x_test = x_test.astype("float32") / 255
# Make sure images have shape (28, 28, 1)
# x_train = np.expand_dims(x_train, -1)
# x_test = np.expand_dims(x_test, -1)
print("x_train shape:", x_train.shape)
print(x_train.shape[0], "train samples")
print(x_test.shape[0], "test samples")


# convert class vectors to binary class matrices
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)
# test_df = tf.keras.utils.to_categorical(test_df, num_classes)

"""### Initialize SHAP Explainer"""

# select a set of background examples to take an expectation over
background = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]

# explain predictions of the model on three images
explainer  = shap.DeepExplainer(model, background)

"""### Compute SHAP Values"""

shap_values = explainer.shap_values(x_test[0:5])

shap_values_combined = np.sum(shap_values[1], axis=-1)  # Combine SHAP values across color channels
abs_max = np.percentile(np.abs(shap_values_combined), 100)
# Normalize the SHAP values to the range [0, 1]
shap_values_normalized = (shap_values_combined - shap_values_combined.min()) / (shap_values_combined.max() - shap_values_combined.min())

"""### Plot SHAP Values"""

# Visualize SHAP values for each color channel separately
fig, axes = plt.subplots(1, 4, figsize=(15, 5))
axes[0].imshow(x_test[1])
axes[0].set_title(f"Original Image")
axes[0].axis('off')
for i, channel in enumerate(["Red", "Green", "Blue"]):
    axes[i + 1].imshow(shap_values_normalized[:,:,i], cmap='seismic', vmin=0, vmax=1)
    axes[i + 1].set_title(f"SHAP values for channel {channel}")
    axes[i + 1].axis('off')

plt.show()